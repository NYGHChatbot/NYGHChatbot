{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = []\n",
        "classes = []\n",
        "word_tag = []\n",
        "\n",
        "ignoring_chars = ['?', '!']\n",
        "\n",
        "data = open('intents.json', encoding = \"utf8\").read()\n",
        "intents = json.loads(data)\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenizing\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        word_tag.append((w, intent['tag']))\n",
        "\n",
        "        #adding to classes\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "\n",
        "#for w in words:\n",
        "#  if w not in ignoring_chars:\n",
        "#    words_lemmatized = lemmatizer.lemmatize(w.lower())\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignoring_chars]\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "#serilaization\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))\n",
        "\n",
        "train_data = []\n",
        "output_data = [0 for element in range(len(classes))]\n",
        "\n",
        "#create our training data\n",
        "for w_tag in word_tag:\n",
        "  bag_of_words = []\n",
        "  pattern_words = w_tag[0]\n",
        "  #for pattern_word in pattern_words:\n",
        "  #  pattern_words_lemmatized = lemmatizer.lemmatize(pattern_word.lower())\n",
        "  pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "  #if word found in current pattern, create bag of words array of 1, otherwise 0\n",
        "  for word in words:\n",
        "    if word in pattern_words:\n",
        "        bag_of_words.append(1)\n",
        "    else:\n",
        "      bag_of_words.append(0)\n",
        "  \n",
        "  #output is 1 for current tag\n",
        "  output_row = list(output_data)\n",
        "  output_row[classes.index(w_tag[1])] = 1\n",
        "\n",
        "  train_data.append([bag_of_words, output_row])\n",
        "\n",
        "random.shuffle(train_data)\n",
        "train_data = np.array(train_data)\n",
        "\n",
        "X_train = list(train_data[:,0]) #patterns\n",
        "Y_train = list(train_data[:,1]) #responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVA8kgdsjKv-",
        "outputId": "77bc5bdd-28ab-4e7b-80b5-fcb4bd79b51d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "<ipython-input-1-2db73b0599e8>:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_data = np.array(train_data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape = (len(X_train[0]),), activation = 'relu')) #first layer with 128 neurons\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation = 'relu')) #second layer with 128/2 neurons\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(Y_train[0]), activation = 'softmax')) #third layer with Y_train[0] neurons\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "#fitting and saving the model\n",
        "fitted_model = model.fit(np.array(X_train), np.array(Y_train), epochs = 350, batch_size = 5, verbose = 1)\n",
        "model.save('model.h5', fitted_model)\n",
        "\n",
        "print(\"model is created.\")"
      ],
      "metadata": {
        "id": "rVCgbxumj_wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acc37bb-c279-4e40-c1f5-3aa3bdcf2cb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "173/173 [==============================] - 2s 3ms/step - loss: 0.0061 - mae: 0.0121\n",
            "Epoch 2/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0120\n",
            "Epoch 3/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0116\n",
            "Epoch 4/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0108\n",
            "Epoch 5/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0100\n",
            "Epoch 6/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0093\n",
            "Epoch 7/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0089\n",
            "Epoch 8/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0081\n",
            "Epoch 9/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0075\n",
            "Epoch 10/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.0033 - mae: 0.0071\n",
            "Epoch 11/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0064\n",
            "Epoch 12/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0060\n",
            "Epoch 13/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0056\n",
            "Epoch 14/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0054\n",
            "Epoch 15/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0050\n",
            "Epoch 16/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0047\n",
            "Epoch 17/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0044\n",
            "Epoch 18/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0042\n",
            "Epoch 19/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0038\n",
            "Epoch 20/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0038\n",
            "Epoch 21/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0036\n",
            "Epoch 22/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0034\n",
            "Epoch 23/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0033\n",
            "Epoch 24/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0030\n",
            "Epoch 25/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0029\n",
            "Epoch 26/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0028\n",
            "Epoch 27/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0027\n",
            "Epoch 28/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0024\n",
            "Epoch 29/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.9819e-04 - mae: 0.0024\n",
            "Epoch 30/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.8464e-04 - mae: 0.0024\n",
            "Epoch 31/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 9.2309e-04 - mae: 0.0023\n",
            "Epoch 32/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 8.6834e-04 - mae: 0.0021\n",
            "Epoch 33/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 8.8644e-04 - mae: 0.0022\n",
            "Epoch 34/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 8.0589e-04 - mae: 0.0021\n",
            "Epoch 35/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.4067e-04 - mae: 0.0021\n",
            "Epoch 36/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 7.6486e-04 - mae: 0.0019\n",
            "Epoch 37/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 7.4020e-04 - mae: 0.0019\n",
            "Epoch 38/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 7.0463e-04 - mae: 0.0018\n",
            "Epoch 39/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 6.8101e-04 - mae: 0.0017\n",
            "Epoch 40/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 7.2571e-04 - mae: 0.0018\n",
            "Epoch 41/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 6.5014e-04 - mae: 0.0017\n",
            "Epoch 42/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 6.5749e-04 - mae: 0.0017\n",
            "Epoch 43/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 6.7903e-04 - mae: 0.0017\n",
            "Epoch 44/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 6.1493e-04 - mae: 0.0016\n",
            "Epoch 45/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 5.6761e-04 - mae: 0.0015\n",
            "Epoch 46/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 5.5183e-04 - mae: 0.0014\n",
            "Epoch 47/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 5.1947e-04 - mae: 0.0013\n",
            "Epoch 48/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 5.9954e-04 - mae: 0.0014\n",
            "Epoch 49/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 5.5577e-04 - mae: 0.0014\n",
            "Epoch 50/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 4.9570e-04 - mae: 0.0013\n",
            "Epoch 51/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 4.7308e-04 - mae: 0.0012\n",
            "Epoch 52/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 4.6535e-04 - mae: 0.0012\n",
            "Epoch 53/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 4.4975e-04 - mae: 0.0011\n",
            "Epoch 54/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 4.9552e-04 - mae: 0.0012\n",
            "Epoch 55/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 4.5491e-04 - mae: 0.0012\n",
            "Epoch 56/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 4.4434e-04 - mae: 0.0011\n",
            "Epoch 57/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 4.4120e-04 - mae: 0.0011\n",
            "Epoch 58/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 4.5283e-04 - mae: 0.0011\n",
            "Epoch 59/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.7089e-04 - mae: 0.0010\n",
            "Epoch 60/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.9130e-04 - mae: 0.0011\n",
            "Epoch 61/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.9617e-04 - mae: 9.7301e-04\n",
            "Epoch 62/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.7785e-04 - mae: 9.8963e-04\n",
            "Epoch 63/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 3.9846e-04 - mae: 0.0010\n",
            "Epoch 64/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.9023e-04 - mae: 9.8817e-04\n",
            "Epoch 65/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.9116e-04 - mae: 9.8207e-04\n",
            "Epoch 66/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 4.1729e-04 - mae: 0.0010\n",
            "Epoch 67/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 3.5792e-04 - mae: 9.1598e-04\n",
            "Epoch 68/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 3.3130e-04 - mae: 8.8486e-04\n",
            "Epoch 69/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.8772e-04 - mae: 9.5778e-04\n",
            "Epoch 70/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 3.2024e-04 - mae: 8.5259e-04\n",
            "Epoch 71/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 3.2696e-04 - mae: 8.4777e-04\n",
            "Epoch 72/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 3.0698e-04 - mae: 8.5717e-04\n",
            "Epoch 73/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 3.1139e-04 - mae: 8.3066e-04\n",
            "Epoch 74/350\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 3.2510e-04 - mae: 8.4638e-04\n",
            "Epoch 75/350\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 3.2476e-04 - mae: 8.5186e-04\n",
            "Epoch 76/350\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 2.9287e-04 - mae: 7.5835e-04\n",
            "Epoch 77/350\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 2.4722e-04 - mae: 7.5018e-04\n",
            "Epoch 78/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.8659e-04 - mae: 7.6269e-04\n",
            "Epoch 79/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.5763e-04 - mae: 6.9036e-04\n",
            "Epoch 80/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 3.0302e-04 - mae: 7.7470e-04\n",
            "Epoch 81/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.4361e-04 - mae: 7.2589e-04\n",
            "Epoch 82/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.9328e-04 - mae: 7.4720e-04\n",
            "Epoch 83/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.7931e-04 - mae: 7.2304e-04\n",
            "Epoch 84/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.6381e-04 - mae: 6.9055e-04\n",
            "Epoch 85/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.5818e-04 - mae: 6.9702e-04\n",
            "Epoch 86/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.4757e-04 - mae: 6.6588e-04\n",
            "Epoch 87/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.5186e-04 - mae: 7.0350e-04\n",
            "Epoch 88/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.7147e-04 - mae: 6.7388e-04\n",
            "Epoch 89/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.6253e-04 - mae: 6.8392e-04\n",
            "Epoch 90/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.4715e-04 - mae: 6.1061e-04\n",
            "Epoch 91/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.8226e-04 - mae: 7.1721e-04\n",
            "Epoch 92/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.3756e-04 - mae: 5.9837e-04\n",
            "Epoch 93/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.6490e-04 - mae: 6.6116e-04\n",
            "Epoch 94/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 2.4966e-04 - mae: 6.4699e-04\n",
            "Epoch 95/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.3995e-04 - mae: 6.0182e-04\n",
            "Epoch 96/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 2.4897e-04 - mae: 5.9214e-04\n",
            "Epoch 97/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 2.2277e-04 - mae: 6.0663e-04\n",
            "Epoch 98/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 2.1058e-04 - mae: 5.6027e-04\n",
            "Epoch 99/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 2.2354e-04 - mae: 5.7623e-04\n",
            "Epoch 100/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.7262e-04 - mae: 7.1146e-04\n",
            "Epoch 101/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.2336e-04 - mae: 5.5179e-04\n",
            "Epoch 102/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.5460e-04 - mae: 6.4752e-04\n",
            "Epoch 103/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.6648e-04 - mae: 6.2078e-04\n",
            "Epoch 104/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.9140e-04 - mae: 5.7632e-04\n",
            "Epoch 105/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.7879e-04 - mae: 6.8674e-04\n",
            "Epoch 106/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.0206e-04 - mae: 5.3603e-04\n",
            "Epoch 107/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.4887e-04 - mae: 6.0357e-04\n",
            "Epoch 108/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.1126e-04 - mae: 5.4188e-04\n",
            "Epoch 109/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.3944e-04 - mae: 5.6989e-04\n",
            "Epoch 110/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.3931e-04 - mae: 5.8913e-04\n",
            "Epoch 111/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.0810e-04 - mae: 5.5591e-04\n",
            "Epoch 112/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.2198e-04 - mae: 5.6779e-04\n",
            "Epoch 113/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.0379e-04 - mae: 5.3724e-04\n",
            "Epoch 114/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.2292e-04 - mae: 5.4107e-04\n",
            "Epoch 115/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.9300e-04 - mae: 4.9495e-04\n",
            "Epoch 116/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.9229e-04 - mae: 4.9365e-04\n",
            "Epoch 117/350\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 1.9935e-04 - mae: 5.2187e-04\n",
            "Epoch 118/350\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 2.4339e-04 - mae: 5.9579e-04\n",
            "Epoch 119/350\n",
            "173/173 [==============================] - 1s 7ms/step - loss: 1.6560e-04 - mae: 4.6922e-04\n",
            "Epoch 120/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.2504e-04 - mae: 5.2901e-04\n",
            "Epoch 121/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.9525e-04 - mae: 5.1015e-04\n",
            "Epoch 122/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.0857e-04 - mae: 5.0156e-04\n",
            "Epoch 123/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 2.0476e-04 - mae: 5.1211e-04\n",
            "Epoch 124/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.7539e-04 - mae: 4.7555e-04\n",
            "Epoch 125/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.0099e-04 - mae: 4.9124e-04\n",
            "Epoch 126/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.1191e-04 - mae: 4.9641e-04\n",
            "Epoch 127/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.6154e-04 - mae: 4.2793e-04\n",
            "Epoch 128/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4180e-04 - mae: 4.1032e-04\n",
            "Epoch 129/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.7978e-04 - mae: 4.5777e-04\n",
            "Epoch 130/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.1372e-04 - mae: 5.2664e-04\n",
            "Epoch 131/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.8933e-04 - mae: 4.5446e-04\n",
            "Epoch 132/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.7801e-04 - mae: 4.7922e-04\n",
            "Epoch 133/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.6504e-04 - mae: 4.1950e-04\n",
            "Epoch 134/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.0444e-04 - mae: 5.0315e-04\n",
            "Epoch 135/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5464e-04 - mae: 3.9599e-04\n",
            "Epoch 136/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.3623e-04 - mae: 3.8738e-04\n",
            "Epoch 137/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.9082e-04 - mae: 4.4814e-04\n",
            "Epoch 138/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3485e-04 - mae: 3.7755e-04\n",
            "Epoch 139/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 2.4004e-04 - mae: 5.3256e-04\n",
            "Epoch 140/350\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 2.3252e-04 - mae: 5.2049e-04\n",
            "Epoch 141/350\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 1.6720e-04 - mae: 4.4324e-04\n",
            "Epoch 142/350\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 1.7981e-04 - mae: 4.3973e-04\n",
            "Epoch 143/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.6007e-04 - mae: 4.1926e-04\n",
            "Epoch 144/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.6216e-04 - mae: 4.0587e-04\n",
            "Epoch 145/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.7148e-04 - mae: 4.6252e-04\n",
            "Epoch 146/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3260e-04 - mae: 3.8550e-04\n",
            "Epoch 147/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.4373e-04 - mae: 3.8304e-04\n",
            "Epoch 148/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.7911e-04 - mae: 4.0676e-04\n",
            "Epoch 149/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.7906e-04 - mae: 3.9291e-04\n",
            "Epoch 150/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.3475e-04 - mae: 3.3844e-04\n",
            "Epoch 151/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.5026e-04 - mae: 3.7593e-04\n",
            "Epoch 152/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.6708e-04 - mae: 4.0023e-04\n",
            "Epoch 153/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.7071e-04 - mae: 3.9535e-04\n",
            "Epoch 154/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4879e-04 - mae: 3.9021e-04\n",
            "Epoch 155/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.4117e-04 - mae: 3.8775e-04\n",
            "Epoch 156/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.2090e-04 - mae: 3.2839e-04\n",
            "Epoch 157/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4641e-04 - mae: 3.7648e-04\n",
            "Epoch 158/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2826e-04 - mae: 3.2811e-04\n",
            "Epoch 159/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.7477e-04 - mae: 4.2119e-04\n",
            "Epoch 160/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.4921e-04 - mae: 4.0621e-04\n",
            "Epoch 161/350\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 2.2747e-04 - mae: 5.0703e-04\n",
            "Epoch 162/350\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 1.5407e-04 - mae: 3.9061e-04\n",
            "Epoch 163/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.7574e-04 - mae: 3.9850e-04\n",
            "Epoch 164/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5577e-04 - mae: 3.5226e-04\n",
            "Epoch 165/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3579e-04 - mae: 3.5712e-04\n",
            "Epoch 166/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5174e-04 - mae: 3.6479e-04\n",
            "Epoch 167/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3920e-04 - mae: 3.7523e-04\n",
            "Epoch 168/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4798e-04 - mae: 3.1570e-04\n",
            "Epoch 169/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1554e-04 - mae: 2.9885e-04\n",
            "Epoch 170/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1451e-04 - mae: 3.1375e-04\n",
            "Epoch 171/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.4470e-04 - mae: 3.8323e-04\n",
            "Epoch 172/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.6785e-04 - mae: 3.9026e-04\n",
            "Epoch 173/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1662e-04 - mae: 3.1132e-04\n",
            "Epoch 174/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4821e-04 - mae: 3.2365e-04\n",
            "Epoch 175/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2298e-04 - mae: 2.7574e-04\n",
            "Epoch 176/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4655e-04 - mae: 3.4629e-04\n",
            "Epoch 177/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5146e-04 - mae: 3.4411e-04\n",
            "Epoch 178/350\n",
            "173/173 [==============================] - 1s 7ms/step - loss: 1.3624e-04 - mae: 3.4727e-04\n",
            "Epoch 179/350\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 1.1737e-04 - mae: 3.0714e-04\n",
            "Epoch 180/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.5737e-04 - mae: 3.6045e-04\n",
            "Epoch 181/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.5982e-04 - mae: 3.6433e-04\n",
            "Epoch 182/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3224e-04 - mae: 3.0070e-04\n",
            "Epoch 183/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4709e-04 - mae: 3.2907e-04\n",
            "Epoch 184/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.3376e-04 - mae: 3.3102e-04\n",
            "Epoch 185/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5603e-04 - mae: 3.5606e-04\n",
            "Epoch 186/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.9170e-04 - mae: 3.8445e-04\n",
            "Epoch 187/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.8483e-04 - mae: 3.7909e-04\n",
            "Epoch 188/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4994e-04 - mae: 3.6337e-04\n",
            "Epoch 189/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.2901e-05 - mae: 2.8099e-04\n",
            "Epoch 190/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.6450e-04 - mae: 3.4882e-04\n",
            "Epoch 191/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.9779e-05 - mae: 2.6367e-04\n",
            "Epoch 192/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1188e-04 - mae: 2.9359e-04\n",
            "Epoch 193/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.4629e-05 - mae: 2.4683e-04\n",
            "Epoch 194/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.0661e-04 - mae: 2.6635e-04\n",
            "Epoch 195/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1002e-04 - mae: 2.7972e-04\n",
            "Epoch 196/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.9077e-05 - mae: 2.4393e-04\n",
            "Epoch 197/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.1471e-04 - mae: 2.8835e-04\n",
            "Epoch 198/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.0557e-04 - mae: 2.8125e-04\n",
            "Epoch 199/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.5102e-04 - mae: 3.4903e-04\n",
            "Epoch 200/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.4023e-04 - mae: 2.9691e-04\n",
            "Epoch 201/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.4302e-04 - mae: 3.0400e-04\n",
            "Epoch 202/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.3175e-04 - mae: 3.0338e-04\n",
            "Epoch 203/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.5666e-04 - mae: 3.3363e-04\n",
            "Epoch 204/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5880e-04 - mae: 3.5475e-04\n",
            "Epoch 205/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.1194e-04 - mae: 3.0651e-04\n",
            "Epoch 206/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.4883e-04 - mae: 3.0643e-04\n",
            "Epoch 207/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 8.1415e-05 - mae: 2.5058e-04\n",
            "Epoch 208/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3299e-04 - mae: 3.0460e-04\n",
            "Epoch 209/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0961e-04 - mae: 2.7506e-04\n",
            "Epoch 210/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.2124e-04 - mae: 2.7816e-04\n",
            "Epoch 211/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.8457e-05 - mae: 2.5376e-04\n",
            "Epoch 212/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4093e-04 - mae: 2.9646e-04\n",
            "Epoch 213/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4930e-04 - mae: 3.0705e-04\n",
            "Epoch 214/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.3460e-04 - mae: 3.0643e-04\n",
            "Epoch 215/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.3150e-04 - mae: 2.7460e-04\n",
            "Epoch 216/350\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 1.0113e-04 - mae: 2.6148e-04\n",
            "Epoch 217/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1864e-04 - mae: 2.6829e-04\n",
            "Epoch 218/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.4899e-05 - mae: 1.9611e-04\n",
            "Epoch 219/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0339e-04 - mae: 2.4648e-04\n",
            "Epoch 220/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0509e-04 - mae: 2.2761e-04\n",
            "Epoch 221/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 2.1297e-04 - mae: 4.0230e-04\n",
            "Epoch 222/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5077e-04 - mae: 2.9349e-04\n",
            "Epoch 223/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.2544e-04 - mae: 2.9146e-04\n",
            "Epoch 224/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.4201e-04 - mae: 2.9624e-04\n",
            "Epoch 225/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0939e-04 - mae: 2.4841e-04\n",
            "Epoch 226/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1060e-04 - mae: 2.4764e-04\n",
            "Epoch 227/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.4487e-04 - mae: 3.2725e-04\n",
            "Epoch 228/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1488e-04 - mae: 2.7934e-04\n",
            "Epoch 229/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0245e-04 - mae: 2.6498e-04\n",
            "Epoch 230/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1287e-04 - mae: 2.7954e-04\n",
            "Epoch 231/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0460e-04 - mae: 2.4350e-04\n",
            "Epoch 232/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2002e-04 - mae: 2.9072e-04\n",
            "Epoch 233/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.2191e-05 - mae: 2.2484e-04\n",
            "Epoch 234/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0499e-04 - mae: 2.5680e-04\n",
            "Epoch 235/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 6.8515e-05 - mae: 2.0165e-04\n",
            "Epoch 236/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4740e-04 - mae: 3.2036e-04\n",
            "Epoch 237/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1087e-04 - mae: 2.9558e-04\n",
            "Epoch 238/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0449e-04 - mae: 2.4511e-04\n",
            "Epoch 239/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1231e-04 - mae: 2.7222e-04\n",
            "Epoch 240/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.2857e-05 - mae: 2.0094e-04\n",
            "Epoch 241/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4422e-04 - mae: 3.1234e-04\n",
            "Epoch 242/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0548e-04 - mae: 2.3218e-04\n",
            "Epoch 243/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1938e-04 - mae: 2.8239e-04\n",
            "Epoch 244/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3546e-04 - mae: 2.7797e-04\n",
            "Epoch 245/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3318e-04 - mae: 2.6966e-04\n",
            "Epoch 246/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0531e-04 - mae: 2.5497e-04\n",
            "Epoch 247/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5938e-04 - mae: 3.3196e-04\n",
            "Epoch 248/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3572e-04 - mae: 2.8651e-04\n",
            "Epoch 249/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 9.0519e-05 - mae: 2.3157e-04\n",
            "Epoch 250/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1054e-04 - mae: 2.3572e-04\n",
            "Epoch 251/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.3425e-04 - mae: 2.6921e-04\n",
            "Epoch 252/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0432e-04 - mae: 2.3844e-04\n",
            "Epoch 253/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.6507e-04 - mae: 3.1731e-04\n",
            "Epoch 254/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.4887e-05 - mae: 2.4505e-04\n",
            "Epoch 255/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0227e-04 - mae: 2.4893e-04\n",
            "Epoch 256/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 6.8978e-05 - mae: 1.9753e-04\n",
            "Epoch 257/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1188e-04 - mae: 2.5835e-04\n",
            "Epoch 258/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.6816e-05 - mae: 2.3178e-04\n",
            "Epoch 259/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3997e-04 - mae: 3.0506e-04\n",
            "Epoch 260/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.8276e-05 - mae: 2.2450e-04\n",
            "Epoch 261/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4682e-04 - mae: 2.9930e-04\n",
            "Epoch 262/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1193e-04 - mae: 2.2439e-04\n",
            "Epoch 263/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.0372e-05 - mae: 2.0010e-04\n",
            "Epoch 264/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0034e-04 - mae: 2.2380e-04\n",
            "Epoch 265/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.3484e-05 - mae: 1.9036e-04\n",
            "Epoch 266/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.6421e-05 - mae: 1.9480e-04\n",
            "Epoch 267/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1080e-04 - mae: 2.2963e-04\n",
            "Epoch 268/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1170e-04 - mae: 2.2036e-04\n",
            "Epoch 269/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.0608e-04 - mae: 2.3757e-04\n",
            "Epoch 270/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 9.3692e-05 - mae: 2.1800e-04\n",
            "Epoch 271/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0159e-04 - mae: 2.2838e-04\n",
            "Epoch 272/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.2272e-04 - mae: 2.5296e-04\n",
            "Epoch 273/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 7.2880e-05 - mae: 1.8504e-04\n",
            "Epoch 274/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4384e-04 - mae: 2.8175e-04\n",
            "Epoch 275/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.5370e-05 - mae: 1.8385e-04\n",
            "Epoch 276/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.1722e-05 - mae: 1.9587e-04\n",
            "Epoch 277/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 7.1128e-05 - mae: 1.8039e-04\n",
            "Epoch 278/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.8959e-05 - mae: 1.8142e-04\n",
            "Epoch 279/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1771e-04 - mae: 2.4010e-04\n",
            "Epoch 280/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.9322e-05 - mae: 2.1150e-04\n",
            "Epoch 281/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.0965e-05 - mae: 1.7558e-04\n",
            "Epoch 282/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3946e-04 - mae: 2.6852e-04\n",
            "Epoch 283/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0770e-04 - mae: 2.2590e-04\n",
            "Epoch 284/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2971e-04 - mae: 2.7688e-04\n",
            "Epoch 285/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.3199e-05 - mae: 1.7895e-04\n",
            "Epoch 286/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0659e-04 - mae: 2.3314e-04\n",
            "Epoch 287/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.7716e-05 - mae: 2.0067e-04\n",
            "Epoch 288/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1124e-04 - mae: 2.3917e-04\n",
            "Epoch 289/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.8278e-04 - mae: 3.1492e-04\n",
            "Epoch 290/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4967e-04 - mae: 2.8257e-04\n",
            "Epoch 291/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 7.4172e-05 - mae: 1.9044e-04\n",
            "Epoch 292/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1303e-04 - mae: 2.2909e-04\n",
            "Epoch 293/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.1409e-04 - mae: 2.3304e-04\n",
            "Epoch 294/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0893e-04 - mae: 2.2326e-04\n",
            "Epoch 295/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.2862e-04 - mae: 2.6796e-04\n",
            "Epoch 296/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0260e-04 - mae: 2.1380e-04\n",
            "Epoch 297/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1816e-04 - mae: 2.4248e-04\n",
            "Epoch 298/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.4942e-04 - mae: 3.1148e-04\n",
            "Epoch 299/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0779e-04 - mae: 2.4055e-04\n",
            "Epoch 300/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3775e-04 - mae: 2.6591e-04\n",
            "Epoch 301/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.3148e-05 - mae: 1.6459e-04\n",
            "Epoch 302/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.1936e-05 - mae: 2.1232e-04\n",
            "Epoch 303/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.5051e-04 - mae: 2.8462e-04\n",
            "Epoch 304/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3091e-04 - mae: 2.6861e-04\n",
            "Epoch 305/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1854e-04 - mae: 2.3193e-04\n",
            "Epoch 306/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1991e-04 - mae: 2.3147e-04\n",
            "Epoch 307/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.9866e-05 - mae: 1.8401e-04\n",
            "Epoch 308/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.0783e-05 - mae: 1.8305e-04\n",
            "Epoch 309/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.0406e-05 - mae: 2.0006e-04\n",
            "Epoch 310/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.0506e-05 - mae: 1.8513e-04\n",
            "Epoch 311/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2236e-04 - mae: 2.3815e-04\n",
            "Epoch 312/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0784e-04 - mae: 2.2936e-04\n",
            "Epoch 313/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2398e-04 - mae: 2.4213e-04\n",
            "Epoch 314/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 9.5781e-05 - mae: 2.1024e-04\n",
            "Epoch 315/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.0491e-04 - mae: 2.2637e-04\n",
            "Epoch 316/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 9.7607e-05 - mae: 2.2159e-04\n",
            "Epoch 317/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.5659e-04 - mae: 2.8145e-04\n",
            "Epoch 318/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1867e-04 - mae: 2.3141e-04\n",
            "Epoch 319/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.7244e-05 - mae: 2.1015e-04\n",
            "Epoch 320/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2323e-04 - mae: 2.5889e-04\n",
            "Epoch 321/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0049e-04 - mae: 2.1811e-04\n",
            "Epoch 322/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0963e-04 - mae: 2.4131e-04\n",
            "Epoch 323/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0332e-04 - mae: 2.2022e-04\n",
            "Epoch 324/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2744e-04 - mae: 2.4166e-04\n",
            "Epoch 325/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.4855e-05 - mae: 1.9269e-04\n",
            "Epoch 326/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1858e-04 - mae: 2.3898e-04\n",
            "Epoch 327/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 7.6193e-05 - mae: 1.8136e-04\n",
            "Epoch 328/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.2692e-05 - mae: 1.8987e-04\n",
            "Epoch 329/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 6.8528e-05 - mae: 1.7722e-04\n",
            "Epoch 330/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.0693e-04 - mae: 2.0374e-04\n",
            "Epoch 331/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 9.2397e-05 - mae: 2.1453e-04\n",
            "Epoch 332/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0117e-04 - mae: 2.2611e-04\n",
            "Epoch 333/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.2964e-05 - mae: 1.5926e-04\n",
            "Epoch 334/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0054e-04 - mae: 2.0070e-04\n",
            "Epoch 335/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 9.5823e-05 - mae: 1.8800e-04\n",
            "Epoch 336/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.5668e-04 - mae: 2.6780e-04\n",
            "Epoch 337/350\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 1.6838e-04 - mae: 2.8724e-04\n",
            "Epoch 338/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 7.4964e-05 - mae: 1.7015e-04\n",
            "Epoch 339/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1108e-04 - mae: 2.4038e-04\n",
            "Epoch 340/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 9.8511e-05 - mae: 2.0287e-04\n",
            "Epoch 341/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.1573e-05 - mae: 2.1929e-04\n",
            "Epoch 342/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.2051e-04 - mae: 2.4301e-04\n",
            "Epoch 343/350\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 1.1449e-04 - mae: 2.3790e-04\n",
            "Epoch 344/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 7.4510e-05 - mae: 1.7469e-04\n",
            "Epoch 345/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.1264e-04 - mae: 2.2127e-04\n",
            "Epoch 346/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 9.2340e-05 - mae: 1.9420e-04\n",
            "Epoch 347/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.2838e-04 - mae: 2.5791e-04\n",
            "Epoch 348/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.3163e-04 - mae: 2.7754e-04\n",
            "Epoch 349/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 1.0550e-04 - mae: 2.1440e-04\n",
            "Epoch 350/350\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 8.3908e-05 - mae: 1.7468e-04\n",
            "model is created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.models import load_model\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "model = load_model('model.h5')\n",
        "intents = json.loads(open('intents.json',encoding=\"utf8\").read())\n",
        "words = pickle.load(open('words.pkl','rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))\n",
        "totalResponseTime = 0\n",
        "numberOfResponses = 0\n",
        "\n",
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern - split words into array\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word - create short form for word\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=True):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - matrix of N words, vocabulary matrix\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s:\n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "def predict_class(sentence, model):\n",
        "    # filter out predictions below a threshold\n",
        "    p = bow(sentence, words,show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "\n",
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "def chatbot_response(msg):\n",
        "    KeyWords = [\"covid-19\", \"covid19\", \"coronavirus\", \"corona virus\", \"covid\", \"corona\", \"mask\", \"masks\",\n",
        "                \"bivalent\", \"antiviral treatments\", \"antiviral treatment\", \"paxlovid\", \"total cases in canada\", \n",
        "                \"statistics report\", \"statistics\", \"total cases\", \"sanitizer\", \"soap\", \"unauthorized vaccine\",\n",
        "                \"hi\", \"hey\", \"hello\", \"greetings\", \"help\", \"what can you do\", \"what you can do\",\n",
        "                \"bye\", \"see you later\", \"goodbye\", \"have a good day\", \"have a nice day\", \"have a good one\",\n",
        "                \"see you soon\", \"have a good night\", \"thanks\", \"thank you\", \"awsome\", \"booster\", \"omicron\",\n",
        "                \"flu\", \"flushot\", \"influenza\", \"monkeypox\", \"monkey pox\", \"children vaccine\", \"vaccine for children\", \n",
        "                \"vaccine for my 5-11 year old\", \"vaccine for my 6 months to 5-year-old\", \n",
        "                \"pay to receive the vaccine\", \"pay for vaccine\", \"pay for the vaccine\", \"vaccine cost\",\n",
        "                \"pfizer\", \"moderna\", \"pregnant\", \"where is north york general hospital located\", \n",
        "                \"where is nygh located\", \"location of north york general hospital\", \n",
        "                \"location of nygh\", \"what is nygh location\", \"what is north york general hospital location\",\n",
        "                \"helpline numbers\", \"on which  number i should call\", \"hospital number\", \"who can i call\",\n",
        "                \"call\", \"nygh hospital number\", \"hospital contact\", \"how do i contact the hospital\", \n",
        "                \"how do i talk to a doctor\",\"how do i talk to a professional\", \"contact hospital\", \"contact pharmacy\"\n",
        "                \"what are the travel guidelines\", \"what are the different approved vaccines\",\n",
        "                \"prophylaxis\", \"what if my pet becomes sick while i am isolating\", \"vaccination\", \"walk-in clinics\",\n",
        "                \"walk in clinics\", \"vaccine\", \"pet becomes sick while i am isolating\", \"north york cough, cold and covid test clinic\",\n",
        "                \"can i bring a support person or family member to my appointment\"]\n",
        "    helper = set()\n",
        "    lowered_case = msg.lower()\n",
        "    for KeyWord in KeyWords:\n",
        "      helper.add(lowered_case.find(KeyWord))\n",
        "    \n",
        "    # for non-related questions\n",
        "    if len(helper) == 1:\n",
        "      return \"Sorry, I don't understand your question. I can only answer questions related to Monkeypox, Influenza (Flu), and Covid-19. If you have any other questions, please contact NYGH's Pharmacy at (416)756-6666 or email them through NYGHPharmacy@nygh.on.ca\"\n",
        " \n",
        "    ints = predict_class(msg, model)\n",
        "    res = getResponse(ints, intents)\n",
        "    return res\n",
        "\n",
        "def startTimer():\n",
        "    start = time.time()\n",
        "    return start\n",
        "\n",
        "def endTimer():\n",
        "    end = time.time()\n",
        "    return end\n",
        "\n",
        "def calculateAverageTime(start, end):\n",
        "    global totalResponseTime\n",
        "    global numberOfResponses\n",
        "\n",
        "    difference = end - start\n",
        "    numberOfResponses = numberOfResponses + 1\n",
        "    totalResponseTime = round(totalResponseTime + difference, 5)\n",
        "    averageResponseTime = totalResponseTime / numberOfResponses\n",
        "\n",
        "    print(\"New Average Response Time: \", averageResponseTime * 1000, \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4yhvXgkKRx",
        "outputId": "8105f37e-059a-452f-b0d2-da7ca7b2178f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_response = input()\n",
        "  str2 = \"no\"\n",
        "  index2 = user_response.lower().find(str2.lower())\n",
        "  if index2 != -1:\n",
        "    print(\"\\nAlright. See you later.\")\n",
        "    break\n",
        "  print(chatbot_response(user_response))\n",
        "  print(\"\\nDid I correctly answer your question?\")\n",
        "  yes_no_response = input()\n",
        "  str1 = \"yes\"\n",
        "  index = yes_no_response.lower().find(str1.lower())\n",
        "  if index != -1:\n",
        "    print(\"\\nGreat! Is there anything else I can help you with?\")\n",
        "    continue\n",
        "  else:\n",
        "    print(\"\\nAlright. You can either ask your question again from me or contact NYGH's Pharmacy at (416)756-6666 or email through NYGHPharmacy@nygh.on.ca\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvL4GZGtkNWZ",
        "outputId": "ae4de945-a69f-4a94-92ad-b5b962c16c72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is monkeypox\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Monkeypox is usually a self-limited viral infection with a rash that may be painful. Most people recover on their own after a few weeks. In some circumstances, people can become very sick and could die.\n",
            "\n",
            "Did I correctly answer your question?\n",
            "yes\n",
            "\n",
            "Great! Is there anything else I can help you with?\n",
            "what is flu\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Influenza, also known as the flu, is a respiratory illness caused primarily by the influenza A and B viruses.\n",
            "\n",
            "Did I correctly answer your question?\n",
            "yes\n",
            "\n",
            "Great! Is there anything else I can help you with?\n",
            "no\n",
            "\n",
            "Alright. See you later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLJmX4vykPP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}